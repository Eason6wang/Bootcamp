{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(\"tensorflow version {}\".format(tf.VERSION)) # make sure its tensorflow 1.*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"b_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#c=a+b\n",
    "#d=c*a\n",
    "g0=tf.Graph()\n",
    "with g0.as_default(): # context manager\n",
    "    a = tf.constant([[1],[2]], dtype=tf.float32,name='a_constant')\n",
    "    b = tf.constant([[2],[3]], dtype=tf.float32,name='b_constant')\n",
    "    c=tf.add(a,b,name='add')  # c = a + b\n",
    "    d=c * a #d = c * a\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "#building the graph (the actual computation does not happen here, though its tempting to think of that)\n",
    "#build the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of a =\n",
      " [[1.]\n",
      " [2.]]\n",
      "value of c =\n",
      " [[3.]\n",
      " [5.]]\n",
      "value of d =\n",
      " [[ 3.]\n",
      " [10.]]\n"
     ]
    }
   ],
   "source": [
    "#computation occurs\n",
    "#start the engine\n",
    "sess0=tf.Session(graph=g0)\n",
    "check = ['a','c','d']\n",
    "result=sess0.run([a,c,d])\n",
    "for i, re in zip(check,result):\n",
    "    print('value of {} =\\n {}'.format(i,re))\n",
    "\n",
    "#visualize the graph\n",
    "writer = tf.summary.FileWriter('.',sess0.graph)\n",
    "writer.flush()\n",
    "\n",
    "sess0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haobei/Projects/Tutorial/L3\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected float32, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-24c83b351a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg0_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mg0_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 353\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "#quiz 1\n",
    "#g0_q=tf.Graph()\n",
    "#c = a @ b\n",
    "#a.shape=(4,2), b.shape=(2,3)\n",
    "g0_q=tf.Graph()\n",
    "with g0_q.as_default():\n",
    "    a = tf.constant(tf.ones(4,2),dtype=tf.float32)\n",
    "    b = tf.constant(tf.ones(2,3),dtype=tf.float32)\n",
    "    c = a @ b\n",
    "sess0q=g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=int32) <tensorflow.python.framework.ops.Graph object at 0xb3f03c0b8>\n",
      "Tensor(\"a_random:0\", shape=(2, 3), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n",
      "Tensor(\"b:0\", shape=(3, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n",
      "name: \"print\"\n",
      "op: \"PrintV2\"\n",
      "input: \"print_format\"\n",
      "attr {\n",
      "  key: \"output_stream\"\n",
      "  value {\n",
      "    s: \"stderr\"\n",
      "  }\n",
      "}\n",
      " <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n",
      "<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref> <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n",
      "Tensor(\"matmul:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n",
      "Tensor(\"add:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f08a3c8>\n"
     ]
    }
   ],
   "source": [
    "#tensor math matrix\n",
    "#with \"defaultGraph\".as_default():\n",
    "g1=tf.Graph()\n",
    "a0 = tf.constant(2)\n",
    "with g1.as_default():\n",
    "    a = tf.random_normal([2,3], dtype=tf.float32,name='a_random')\n",
    "    b = tf.constant([[1,1],[1,1],[1,1]], dtype=tf.float32,name='b')\n",
    "    op = tf.print(\"value of a\",a,name='print')\n",
    "    var_x = tf.get_variable(\"var_x\", [2,2], dtype=tf.float32, trainable=True,\n",
    "                            initializer=tf.glorot_normal_initializer)\n",
    "    c = tf.matmul(a,b,name='matmul') # a @ b\n",
    "    d = c + var_x #tf.add\n",
    "print(a0,a0.graph)\n",
    "print(a,a.graph)\n",
    "print(b,b.graph)\n",
    "print(op,op.graph)\n",
    "print(var_x,var_x.graph)\n",
    "print(c,c.graph)\n",
    "print(d,d.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine switch\n",
    "sess1=tf.Session(graph=g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print None\n",
      "a [[ 0.49499008  1.9555719  -0.7545054 ]\n",
      " [ 0.45289025 -1.7964365   0.3596094 ]]\n",
      "matmul None\n",
      "c [[-0.8689999 -0.8689999]\n",
      " [ 1.8697393  1.8697393]]\n",
      "a,c [array([[-0.06084506,  0.36236683,  0.27671674],\n",
      "       [ 0.4164595 , -1.4819223 , -0.2758948 ]], dtype=float32), array([[ 0.5782385,  0.5782385],\n",
      "       [-1.3413576, -1.3413576]], dtype=float32), array([[-0.06084506,  0.36236683,  0.27671674],\n",
      "       [ 0.4164595 , -1.4819223 , -0.2758948 ]], dtype=float32)]\n",
      "d [[-5.1564226  -5.419283  ]\n",
      " [ 0.28008488  0.34103048]]\n",
      "var_x [[ 0.12384737 -0.13901274]\n",
      " [ 0.33427343  0.39521903]]\n",
      "d [[ 2.6236043  2.360744 ]\n",
      " [-0.3076128 -0.2466672]]\n",
      "assign [[ 1.1238474  -0.13901274]\n",
      " [ 1.3342735   1.3952191 ]]\n",
      "var_x,d [array([[ 1.1238474 , -0.13901274],\n",
      "       [ 1.3342735 ,  1.3952191 ]], dtype=float32), array([[2.4343586 , 1.1714984 ],\n",
      "       [0.45895058, 0.5198962 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('print',sess1.run(op))\n",
    "print('a',sess1.run(a)) #print(a.eval(session=sess))\n",
    "print('matmul',sess1.run('matmul'))\n",
    "print('c',sess1.run(c)) #c\n",
    "print('a,c',sess1.run([a,c,a]))\n",
    "# print('initilizer',sess1.run(var_x.initializer))\n",
    "with g1.as_default():\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "print('d',sess1.run(d))\n",
    "print('var_x',sess1.run(var_x))\n",
    "print('d',sess1.run(d))\n",
    "print('assign',sess1.run(var_x.assign_add([[1,0],[1,1]])))\n",
    "print('var_x,d',sess1.run([var_x,d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess1.graph)\n",
    "writer.flush()\n",
    "tf.reset_default_graph()\n",
    "v = tf.get_variable(\"d\",shape=[2,3],dtype=tf.float32,initializer=tf.glorot_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Variable 'd:0' shape=(2, 3) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "#facilitate updates of weights of a neural network\n",
    "with g1.as_default():\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "    print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)) \n",
    "    print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiz 2\n",
    "#g1_q=tf.Graph()\n",
    "#d = tf.reduce_sum(var_w * ((L @ x)^2)) + var_b\n",
    "# var_w.shape=(2,) L.shape=(2,3) x.shape=(3,1) var_b.shape=() initializer: tf.random_normal_initializer\n",
    "g1_q=tf.Graph()\n",
    "with g1_q.as_default():\n",
    "    x = tf.constant([[0],[1],[2]],dtype=tf.float32)\n",
    "    var_w = tf.get_variable('var_w',shape=(2,1),dtype=tf.float32,initializer=tf.ones_initializer)\n",
    "    L = tf.constant([[0,1,2],[2,3,4]],name='L',dtype=tf.float32)\n",
    "    var_b = tf.get_variable('var_b',shape=(),dtype=tf.float32,initializer=tf.ones_initializer)\n",
    "    d=tf.reduce_sum(var_w * tf.square(L @ x))+var_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.0\n"
     ]
    }
   ],
   "source": [
    "sess_g1_q = tf.Session(graph=g1_q)\n",
    "# sess_g1_q.run([var_w.initializer,var_b.initializer])\n",
    "with g1_q.as_default():\n",
    "    sess_g1_q.run(tf.global_variables_initializer())\n",
    "print(sess_g1_q.run(d))\n",
    "writer = tf.summary.FileWriter('.',sess_g1_q.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1], [2], [3], [4]],dtype=np.float32)\n",
    "y = np.array([[4], [3], [2], [1]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default graph\n",
    "tf.reset_default_graph()\n",
    "# mini-batch \n",
    "x_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"x_placeholder\") # shape is determained at runtime\n",
    "y_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"y_placeholder\")\n",
    "\n",
    "W = tf.get_variable(\"weight\",shape=(),dtype=tf.float32,\n",
    "                    initializer=tf.ones_initializer,\n",
    "                    trainable=True)\n",
    "b = tf.get_variable(\"bias\",shape=(),dtype=tf.float32,\n",
    "                    initializer=tf.zeros_initializer,\n",
    "                    trainable=True)\n",
    "y_hat = W * x_p + b\n",
    "loss = tf.reduce_mean(tf.square(y_hat - y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session() # session of the default graph\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = tf.gradients(loss,[W,b])\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0]\n",
      "[array([[1.],\n",
      "       [2.],\n",
      "       [3.],\n",
      "       [4.]], dtype=float32), 5.0, [5.0, 0.0]]\n",
      "0 gradient:  [5.0, 0.0] \t 1.0 0.0 ==> -4.0 0.0\n",
      "1 gradient:  [-70.0, -25.0] \t -4.0 0.0 ==> 66.0 25.0\n",
      "2 gradient:  [1105.0, 375.0] \t 66.0 25.0 ==> -1039.0 -350.0\n",
      "3 gradient:  [-17345.0, -5900.0] \t -1039.0 -350.0 ==> 16306.0 5550.0\n",
      "4 gradient:  [272330.0, 92625.0] \t 16306.0 5550.0 ==> -256024.0 -87075.0\n",
      "5 gradient:  [-4275745.0, -1454275.0] \t -256024.0 -87075.0 ==> 4019721.0 1367200.0\n",
      "6 gradient:  [67131810.0, 22833000.0] \t 4019721.0 1367200.0 ==> -63112090.0 -21465800.0\n",
      "7 gradient:  [-1054010300.0, -358492030.0] \t -63112090.0 -21465800.0 ==> 990898240.0 337026240.0\n",
      "8 gradient:  [16548604000.0, 5628544000.0] \t 990898240.0 337026240.0 ==> -15557706000.0 -5291518000.0\n",
      "9 gradient:  [-259823170000.0, -88371560000.0] \t -15557706000.0 -5291518000.0 ==> 244265470000.0 83080045000.0\n",
      "10 gradient:  [4079382200000.0, 1387487400000.0] \t 244265470000.0 83080045000.0 ==> -3835116700000.0 -1304407400000.0\n",
      "11 gradient:  [-64048790000000.0, -21784397000000.0] \t -3835116700000.0 -1304407400000.0 ==> 60213676000000.0 20479990000000.0\n",
      "12 gradient:  [1005605100000000.0, 342028380000000.0] \t 60213676000000.0 20479990000000.0 ==> -945391400000000.0 -321548400000000.0\n",
      "13 gradient:  [-1.5788613e+16, -5370054000000000.0] \t -945391400000000.0 -321548400000000.0 ==> 1.4843222e+16 5048505300000000.0\n",
      "14 gradient:  [2.4789088e+17, 8.431313e+16] \t 1.4843222e+16 5048505300000000.0 ==> -2.3304766e+17 -7.926463e+16\n",
      "15 gradient:  [-3.8920378e+18, -1.3237675e+18] \t -2.3304766e+17 -7.926463e+16 ==> 3.6589903e+18 1.2445029e+18\n",
      "16 gradient:  [6.110737e+19, 2.0783958e+19] \t 3.6589903e+18 1.2445029e+18 ==> -5.744838e+19 -1.9539456e+19\n",
      "17 gradient:  [-9.5942294e+20, -3.263208e+20] \t -5.744838e+19 -1.9539456e+19 ==> 9.019745e+20 3.0678134e+20\n",
      "18 gradient:  [1.5063525e+22, 5.1234357e+21] \t 9.019745e+20 3.0678134e+20 ==> -1.4161551e+22 -4.8166544e+21\n",
      "19 gradient:  [-2.3650653e+23, -8.044106e+22] \t -1.4161551e+22 -4.8166544e+21 ==> 2.2234498e+23 7.562441e+22\n",
      "20 gradient:  [3.713297e+24, 1.2629738e+24] \t 2.2234498e+23 7.562441e+22 ==> -3.490952e+24 -1.1873493e+24\n",
      "21 gradient:  [-5.8301027e+25, -1.982946e+25] \t -3.490952e+24 -1.1873493e+24 ==> 5.4810073e+25 1.864211e+25\n",
      "22 gradient:  [9.153617e+26, 3.113346e+26] \t 5.4810073e+25 1.864211e+25 ==> -8.605516e+26 -2.9269248e+26\n",
      "23 gradient:  [-1.4371736e+28, -4.8881434e+27] \t -8.605516e+26 -2.9269248e+26 ==> 1.3511184e+28 4.5954508e+27\n",
      "24 gradient:  [2.2564502e+29, 7.6746823e+28] \t 1.3511184e+28 4.5954508e+27 ==> -2.1213384e+29 -7.215137e+28\n",
      "25 gradient:  [-3.5427644e+30, -1.2049719e+30] \t -2.1213384e+29 -7.215137e+28 ==> 3.3306305e+30 1.13282054e+30\n",
      "26 gradient:  [5.562356e+31, 1.8918793e+31] \t 3.3306305e+30 1.13282054e+30 ==> -5.2292933e+31 -1.7785973e+31\n",
      "27 gradient:  [-8.733238e+32, -2.9703661e+32] \t -5.2292933e+31 -1.7785973e+31 ==> 8.210309e+32 2.7925065e+32\n",
      "28 gradient:  [1.3711719e+34, 4.6636562e+33] \t 8.210309e+32 2.7925065e+32 ==> -1.2890687e+34 -4.3844054e+33\n",
      "29 gradient:  [-2.1528233e+35, -7.322224e+34] \t -1.2890687e+34 -4.3844054e+33 ==> 2.0239165e+35 6.8837835e+34\n",
      "30 gradient:  [3.380064e+36, 1.1496339e+36] \t 2.0239165e+35 6.8837835e+34 ==> -3.1776724e+36 -1.08079605e+36\n",
      "31 gradient:  [-5.3069067e+37, -1.8049954e+37] \t -3.1776724e+36 -1.08079605e+36 ==> 4.9891396e+37 1.6969158e+37\n",
      "32 gradient:  [inf, inf] \t 4.9891396e+37 1.6969158e+37 ==> -inf -inf\n",
      "33 gradient:  [-inf, -inf] \t -inf -inf ==> nan nan\n",
      "34 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "35 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "36 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "37 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "38 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "39 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "40 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "41 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "42 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "43 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "44 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "45 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "46 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "47 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "48 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "49 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "50 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "51 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "52 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "53 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "54 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "55 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "56 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "57 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "58 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "59 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "60 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "61 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "62 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "63 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "64 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "65 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "66 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "67 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "68 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "69 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "70 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "71 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "72 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "73 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "74 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "75 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "76 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "77 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "78 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "79 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "80 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "81 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "82 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "83 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "84 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "85 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "86 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "87 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "88 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "89 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "90 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "91 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "92 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "93 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "94 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "95 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "96 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "97 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "98 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "99 gradient:  [nan, nan] \t nan nan ==> nan nan\n",
      "[nan, nan]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "W_init = sess.run([W,b])\n",
    "print(W_init)\n",
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(prediction)\n",
    "for i in range(100):\n",
    "    grad=sess.run(gradient,feed_dict={x_p: x,y_p: y})\n",
    "    W_old,b_old = sess.run([W,b])\n",
    "    sess.run([W.assign_sub(0.1*grad[0]),b.assign_sub(0.1*grad[1])]) #what about millions of weights?\n",
    "#     sess.run([var.assign_sub(0.1*gradient) for var,gradient in zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES),grad)])\n",
    "    W_new,b_new = sess.run([W,b])\n",
    "    print(i,\"gradient: \",grad, \"\\t\", W_old,b_old, \"==>\",W_new,b_new)\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "[[1.5107338]\n",
      " [1.7937801]\n",
      " [2.0768263]\n",
      " [2.3598723]]\n",
      "target\n",
      "[[4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(\"prediction\")\n",
    "print(prediction[0])\n",
    "print(\"target\")\n",
    "print(y)\n",
    "# 1000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[0],[1],[1]])\n",
    "#tf.sigmoid() tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your implementation goes here, add more code cells if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on () two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## 1. What is tensorflow?\n",
    "## 2. Why do people use tensorflow?\n",
    "## 3. How to write tensorflow program?\n",
    "### (1). Build dataflow graph\n",
    "### (2). Run dataflow graph and train the weights\n",
    "## 4. (Bonus) What is feature learning and feature crafting (feature engineering), Difference, how to do feature crafting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "## 2.\n",
    "\n",
    "## 3.(1). \n",
    "\n",
    "## 3.(2).\n",
    "\n",
    "## 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
