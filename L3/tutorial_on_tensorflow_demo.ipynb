{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(\"tensorflow version {}\".format(tf.VERSION)) # make sure its tensorflow 1.*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"b_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#c=a+b\n",
    "#d=c*a\n",
    "g0=tf.Graph()\n",
    "with g0.as_default(): # context manager\n",
    "    a = tf.constant([[1],[2]], dtype=tf.float32,name='a_constant')\n",
    "    b = tf.constant([[2],[3]], dtype=tf.float32,name='b_constant')\n",
    "    c=tf.add(a,b,name='add')  # c = a + b\n",
    "    d=c * a #d = c * a\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "#building the graph (the actual computation does not happen here, though its tempting to think of that)\n",
    "#build the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of a =\n",
      " [[1.]\n",
      " [2.]]\n",
      "value of c =\n",
      " [[3.]\n",
      " [5.]]\n",
      "value of d =\n",
      " [[ 3.]\n",
      " [10.]]\n"
     ]
    }
   ],
   "source": [
    "#computation occurs\n",
    "#start the engine\n",
    "sess0=tf.Session(graph=g0)\n",
    "check = ['a','c','d']\n",
    "result=sess0.run([a,c,d])\n",
    "for i, re in zip(check,result):\n",
    "    print('value of {} =\\n {}'.format(i,re))\n",
    "\n",
    "#visualize the graph\n",
    "writer = tf.summary.FileWriter('.',sess0.graph)\n",
    "writer.flush()\n",
    "\n",
    "sess0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haobei/Projects/Tutorial/L3\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected float32, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-24c83b351a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mg0_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mg0_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 353\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected float32, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "#quiz 1\n",
    "#g0_q=tf.Graph()\n",
    "#c = a @ b\n",
    "#a.shape=(4,2), b.shape=(2,3)\n",
    "g0_q=tf.Graph()\n",
    "with g0_q.as_default():\n",
    "    a = tf.constant(tf.ones(4,2),dtype=tf.float32)\n",
    "    b = tf.constant(tf.ones(2,3),dtype=tf.float32)\n",
    "    c = a @ b\n",
    "sess0q=g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=int32) <tensorflow.python.framework.ops.Graph object at 0xb3b4e9b00>\n",
      "Tensor(\"a_random:0\", shape=(2, 3), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n",
      "Tensor(\"b:0\", shape=(3, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n",
      "name: \"print\"\n",
      "op: \"PrintV2\"\n",
      "input: \"print_format\"\n",
      "attr {\n",
      "  key: \"output_stream\"\n",
      "  value {\n",
      "    s: \"stderr\"\n",
      "  }\n",
      "}\n",
      " <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n",
      "<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref> <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n",
      "Tensor(\"matmul:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n",
      "Tensor(\"add:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3f0de080>\n"
     ]
    }
   ],
   "source": [
    "#tensor math matrix\n",
    "#with \"defaultGraph\".as_default():\n",
    "g1=tf.Graph()\n",
    "a0 = tf.constant(2)\n",
    "with g1.as_default():\n",
    "    a = tf.random_normal([2,3], dtype=tf.float32,name='a_random')\n",
    "    b = tf.constant([[1,1],[1,1],[1,1]], dtype=tf.float32,name='b')\n",
    "    op = tf.print(\"value of a\",a,name='print')\n",
    "    var_x = tf.get_variable(\"var_x\", [2,2], dtype=tf.float32, trainable=True,\n",
    "                            initializer=tf.glorot_normal_initializer)\n",
    "    c = tf.matmul(a,b,name='matmul') # a @ b\n",
    "    d = c + var_x #tf.add\n",
    "print(a0,a0.graph)\n",
    "print(a,a.graph)\n",
    "print(b,b.graph)\n",
    "print(op,op.graph)\n",
    "print(var_x,var_x.graph)\n",
    "print(c,c.graph)\n",
    "print(d,d.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine switch\n",
    "sess1=tf.Session(graph=g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print None\n",
      "a [[ 1.8965936   0.67290306  0.38004753]\n",
      " [ 0.6080279  -1.3229957   0.53101563]]\n",
      "matmul None\n",
      "c [[-2.360977 -2.360977]\n",
      " [-0.931275 -0.931275]]\n",
      "a,c [array([[0.03357645, 0.672558  , 0.56179285],\n",
      "       [1.1359289 , 0.03175025, 0.53392935]], dtype=float32), array([[1.2679273, 1.2679273],\n",
      "       [1.7016084, 1.7016084]], dtype=float32), array([[0.03357645, 0.672558  , 0.56179285],\n",
      "       [1.1359289 , 0.03175025, 0.53392935]], dtype=float32)]\n",
      "d [[ 0.84133595 -0.20170203]\n",
      " [ 0.04592577  0.09867543]]\n",
      "var_x [[ 0.78981847 -0.25321952]\n",
      " [ 0.30114126  0.35389093]]\n",
      "d [[-3.6264184  -4.6694565 ]\n",
      " [-0.99057496 -0.9378253 ]]\n",
      "assign [[ 1.7898185  -0.25321952]\n",
      " [ 1.3011413   1.3538909 ]]\n",
      "var_x,d [array([[ 1.7898185 , -0.25321952],\n",
      "       [ 1.3011413 ,  1.3538909 ]], dtype=float32), array([[ 1.8856635 , -0.15737459],\n",
      "       [-0.6366663 , -0.58391666]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print('print',sess1.run(op))\n",
    "print('a',sess1.run(a)) #print(a.eval(session=sess))\n",
    "print('matmul',sess1.run('matmul'))\n",
    "print('c',sess1.run(c)) #c\n",
    "print('a,c',sess1.run([a,c,a]))\n",
    "# print('initilizer',sess1.run(var_x.initializer))\n",
    "with g1.as_default():\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "print('d',sess1.run(d))\n",
    "print('var_x',sess1.run(var_x))\n",
    "print('d',sess1.run(d))\n",
    "print('assign',sess1.run(var_x.assign_add([[1,0],[1,1]])))\n",
    "print('var_x,d',sess1.run([var_x,d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess1.graph)\n",
    "writer.flush()\n",
    "tf.reset_default_graph()\n",
    "v = tf.get_variable(\"d\",shape=[2,3],dtype=tf.float32,initializer=tf.glorot_normal_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Variable 'd:0' shape=(2, 3) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "#facilitate updates of weights of a neural network\n",
    "with g1.as_default():\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "    print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)) \n",
    "    print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quiz 2\n",
    "#g1_q=tf.Graph()\n",
    "#d = tf.reduce_sum(var_w * ((L @ x)^2)) + var_b\n",
    "# var_w.shape=(2,) L.shape=(2,3) x.shape=(3,1) var_b.shape=() initializer: tf.random_normal_initializer\n",
    "g1_q=tf.Graph()\n",
    "with g1_q.as_default():\n",
    "    x = tf.constant([[0],[1],[2]],dtype=tf.float32)\n",
    "    var_w = tf.get_variable('var_w',shape=(2,1),dtype=tf.float32,initializer=tf.ones_initializer)\n",
    "    L = tf.constant([[0,1,2],[2,3,4]],name='L',dtype=tf.float32)\n",
    "    var_b = tf.get_variable('var_b',shape=(),dtype=tf.float32,initializer=tf.ones_initializer)\n",
    "    d=tf.reduce_sum(var_w * tf.square(L @ x))+var_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.0\n"
     ]
    }
   ],
   "source": [
    "sess_g1_q = tf.Session(graph=g1_q)\n",
    "# sess_g1_q.run([var_w.initializer,var_b.initializer])\n",
    "with g1_q.as_default():\n",
    "    sess_g1_q.run(tf.global_variables_initializer())\n",
    "print(sess_g1_q.run(d))\n",
    "writer = tf.summary.FileWriter('.',sess_g1_q.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1], [2], [3], [4]],dtype=np.float32)\n",
    "y = np.array([[4], [3], [2], [1]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default graph\n",
    "tf.reset_default_graph()\n",
    "# mini-batch \n",
    "x_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"x_placeholder\") # shape is determained at runtime\n",
    "y_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"y_placeholder\")\n",
    "\n",
    "W = tf.get_variable(\"weight\",shape=(),dtype=tf.float32,\n",
    "                    initializer=tf.ones_initializer,\n",
    "                    trainable=True)\n",
    "b = tf.get_variable(\"bias\",shape=(),dtype=tf.float32,\n",
    "                    initializer=tf.zeros_initializer,\n",
    "                    trainable=True)\n",
    "y_hat = W * x_p + b\n",
    "loss = tf.reduce_mean(tf.square(y_hat - y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session() # session of the default graph\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = tf.gradients(loss,[W,b])\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0]\n",
      "[array([[1.],\n",
      "       [2.],\n",
      "       [3.],\n",
      "       [4.]], dtype=float32), 5.0, [5.0, 0.0]]\n",
      "0 gradient:  [5.0, 0.0] \t 1.0 0.0 ==> 0.5 0.0\n",
      "1 gradient:  [-2.5, -2.5] \t 0.5 0.0 ==> 0.75 0.25\n",
      "2 gradient:  [2.5, -0.75] \t 0.75 0.25 ==> 0.5 0.325\n",
      "3 gradient:  [-0.87499976, -1.8499999] \t 0.5 0.325 ==> 0.5875 0.51\n",
      "4 gradient:  [1.3624997, -1.0425001] \t 0.5875 0.51 ==> 0.45125002 0.61425\n",
      "5 gradient:  [-0.15999997, -1.51525] \t 0.45125002 0.61425 ==> 0.46725002 0.76577497\n",
      "6 gradient:  [0.8376254, -1.1321999] \t 0.46725002 0.76577497 ==> 0.38348746 0.87899494\n",
      "7 gradient:  [0.14728665, -1.3245728] \t 0.38348746 0.87899494 ==> 0.3687588 1.0114522\n",
      "8 gradient:  [0.5886431, -1.1333016] \t 0.3687588 1.0114522 ==> 0.3098945 1.1247823\n",
      "9 gradient:  [0.2723291, -1.2009628] \t 0.3098945 1.1247823 ==> 0.2826616 1.2448786\n",
      "10 gradient:  [0.46431732, -1.0969347] \t 0.2826616 1.2448786 ==> 0.23622985 1.354572\n",
      "11 gradient:  [0.31630778, -1.1097066] \t 0.23622985 1.354572 ==> 0.20459908 1.4655427\n",
      "12 gradient:  [0.39669943, -1.0459193] \t 0.20459908 1.4655427 ==> 0.16492914 1.5701346\n",
      "13 gradient:  [0.32461047, -1.035085] \t 0.16492914 1.5701346 ==> 0.13246809 1.6736431\n",
      "14 gradient:  [0.355237, -0.99037325] \t 0.13246809 1.6736431 ==> 0.09694439 1.7726804\n",
      "15 gradient:  [0.31756806, -0.9699172] \t 0.09694439 1.7726804 ==> 0.06518759 1.8696721\n",
      "16 gradient:  [0.32617414, -0.9347179] \t 0.06518759 1.8696721 ==> 0.032570176 1.9631438\n",
      "17 gradient:  [0.30427182, -0.9108615] \t 0.032570176 1.9631438 ==> 0.0021429937 2.05423\n",
      "18 gradient:  [0.30329454, -0.88082516] \t 0.0021429937 2.05423 ==> -0.028186461 2.1423125\n",
      "19 gradient:  [0.2887658, -0.85630727] \t -0.028186461 2.1423125 ==> -0.05706304 2.2279432\n",
      "20 gradient:  [0.28377044, -0.8294288] \t -0.05706304 2.2279432 ==> -0.085440084 2.3108861\n",
      "21 gradient:  [0.2728294, -0.80542815] \t -0.085440084 2.3108861 ==> -0.11272302 2.391429\n",
      "22 gradient:  [0.26629937, -0.78075725] \t -0.11272302 2.391429 ==> -0.13935296 2.4695046\n",
      "23 gradient:  [0.2572285, -0.75775564] \t -0.13935296 2.4695046 ==> -0.16507581 2.5452802\n",
      "24 gradient:  [0.25026417, -0.7348185] \t -0.16507581 2.5452802 ==> -0.19010222 2.618762\n",
      "25 gradient:  [0.24227667, -0.71298707] \t -0.19010222 2.618762 ==> -0.21432988 2.6900606\n",
      "26 gradient:  [0.23535478, -0.6915282] \t -0.21432988 2.6900606 ==> -0.23786536 2.7592134\n",
      "27 gradient:  [0.22808683, -0.6708999] \t -0.23786536 2.7592134 ==> -0.26067403 2.8263035\n",
      "28 gradient:  [0.22140718, -0.6507631] \t -0.26067403 2.8263035 ==> -0.28281474 2.8913798\n",
      "29 gradient:  [0.21467805, -0.63131404] \t -0.28281474 2.8913798 ==> -0.30428255 2.9545112\n",
      "30 gradient:  [0.20831776, -0.6123904] \t -0.30428255 2.9545112 ==> -0.3251143 3.0157502\n",
      "31 gradient:  [0.20203602, -0.59407127] \t -0.3251143 3.0157502 ==> -0.3453179 3.0751574\n",
      "32 gradient:  [0.19601834, -0.57627475] \t -0.3453179 3.0751574 ==> -0.36491972 3.1327848\n",
      "33 gradient:  [0.19012845, -0.55902886] \t -0.36491972 3.1327848 ==> -0.38393256 3.1886878\n",
      "34 gradient:  [0.18445039, -0.5422873] \t -0.38393256 3.1886878 ==> -0.4023776 3.2429166\n",
      "35 gradient:  [0.17891884, -0.52605486] \t -0.4023776 3.2429166 ==> -0.4202695 3.295522\n",
      "36 gradient:  [0.17356753, -0.5103035] \t -0.4202695 3.295522 ==> -0.43762624 3.3465524\n",
      "37 gradient:  [0.16836834, -0.49502647] \t -0.43762624 3.3465524 ==> -0.45446306 3.396055\n",
      "38 gradient:  [0.16332877, -0.48020542] \t -0.45446306 3.396055 ==> -0.47079593 3.4440756\n",
      "39 gradient:  [0.15843904, -0.46582842] \t -0.47079593 3.4440756 ==> -0.48663983 3.4906585\n",
      "40 gradient:  [0.15369523, -0.45188206] \t -0.48663983 3.4906585 ==> -0.50200933 3.5358467\n",
      "41 gradient:  [0.14909351, -0.4383533] \t -0.50200933 3.5358467 ==> -0.51691866 3.579682\n",
      "42 gradient:  [0.14463067, -0.42522907] \t -0.51691866 3.579682 ==> -0.5313817 3.622205\n",
      "43 gradient:  [0.14029932, -0.4124986] \t -0.5313817 3.622205 ==> -0.54541165 3.6634548\n",
      "44 gradient:  [0.13609898, -0.40014875] \t -0.54541165 3.6634548 ==> -0.55902153 3.7034698\n",
      "45 gradient:  [0.13202584, -0.3881681] \t -0.55902153 3.7034698 ==> -0.57222414 3.7422867\n",
      "46 gradient:  [0.12807131, -0.37654734] \t -0.57222414 3.7422867 ==> -0.5850313 3.7799413\n",
      "47 gradient:  [0.12423754, -0.3652737] \t -0.5850313 3.7799413 ==> -0.597455 3.8164687\n",
      "48 gradient:  [0.12051821, -0.3543377] \t -0.597455 3.8164687 ==> -0.60950685 3.8519025\n",
      "49 gradient:  [0.11690974, -0.34372926] \t -0.60950685 3.8519025 ==> -0.6211978 3.8862753\n",
      "50 gradient:  [0.11340904, -0.33343852] \t -0.6211978 3.8862753 ==> -0.63253874 3.919619\n",
      "51 gradient:  [0.11001432, -0.32345557] \t -0.63253874 3.919619 ==> -0.64354014 3.9519646\n",
      "52 gradient:  [0.106720924, -0.3137715] \t -0.64354014 3.9519646 ==> -0.65421224 3.9833417\n",
      "53 gradient:  [0.10352492, -0.3043778] \t -0.65421224 3.9833417 ==> -0.6645647 4.0137796\n",
      "54 gradient:  [0.10042715, -0.29526436] \t -0.6645647 4.0137796 ==> -0.67460746 4.043306\n",
      "55 gradient:  [0.097417474, -0.2864256] \t -0.67460746 4.043306 ==> -0.6843492 4.0719485\n",
      "56 gradient:  [0.09450483, -0.27784884] \t -0.6843492 4.0719485 ==> -0.6937997 4.0997334\n",
      "57 gradient:  [0.091671586, -0.26953173] \t -0.6937997 4.0997334 ==> -0.7029668 4.1266866\n",
      "58 gradient:  [0.08893061, -0.2614609] \t -0.7029668 4.1266866 ==> -0.7118599 4.1528325\n",
      "59 gradient:  [0.08626425, -0.25363445] \t -0.7118599 4.1528325 ==> -0.7204863 4.178196\n",
      "60 gradient:  [0.0836854, -0.24603951] \t -0.7204863 4.178196 ==> -0.72885484 4.2028\n",
      "61 gradient:  [0.0811764, -0.23867464] \t -0.72885484 4.2028 ==> -0.73697245 4.2266674\n",
      "62 gradient:  [0.07875013, -0.23152745] \t -0.73697245 4.2266674 ==> -0.7448475 4.24982\n",
      "63 gradient:  [0.076388955, -0.22459698] \t -0.7448475 4.24982 ==> -0.75248635 4.2722797\n",
      "64 gradient:  [0.074103355, -0.21787226] \t -0.75248635 4.2722797 ==> -0.7598967 4.294067\n",
      "65 gradient:  [0.071884036, -0.21134973] \t -0.7598967 4.294067 ==> -0.7670851 4.3152018\n",
      "66 gradient:  [0.069732666, -0.20502186] \t -0.7670851 4.3152018 ==> -0.77405834 4.335704\n",
      "67 gradient:  [0.06764412, -0.19888401] \t -0.77405834 4.335704 ==> -0.78082275 4.3555923\n",
      "68 gradient:  [0.065619946, -0.19292927] \t -0.78082275 4.3555923 ==> -0.78738475 4.374885\n",
      "69 gradient:  [0.063654184, -0.18715358] \t -0.78738475 4.374885 ==> -0.79375017 4.3936005\n",
      "70 gradient:  [0.061749935, -0.1815499] \t -0.79375017 4.3936005 ==> -0.79992515 4.4117556\n",
      "71 gradient:  [0.05990064, -0.17611456] \t -0.79992515 4.4117556 ==> -0.80591524 4.429367\n",
      "72 gradient:  [0.0581069, -0.17084205] \t -0.80591524 4.429367 ==> -0.8117259 4.446451\n",
      "73 gradient:  [0.056367278, -0.16572714] \t -0.8117259 4.446451 ==> -0.81736267 4.463024\n",
      "74 gradient:  [0.054680824, -0.16076505] \t -0.81736267 4.463024 ==> -0.82283074 4.4791007\n",
      "75 gradient:  [0.05304253, -0.15595222] \t -0.82283074 4.4791007 ==> -0.828135 4.494696\n",
      "76 gradient:  [0.051455498, -0.15128279] \t -0.828135 4.494696 ==> -0.83328056 4.5098243\n",
      "77 gradient:  [0.04991293, -0.14675426] \t -0.83328056 4.5098243 ==> -0.83827186 4.5245\n",
      "78 gradient:  [0.04842162, -0.1423595] \t -0.83827186 4.5245 ==> -0.843114 4.538736\n",
      "79 gradient:  [0.046968937, -0.13809836] \t -0.843114 4.538736 ==> -0.8478109 4.5525455\n",
      "80 gradient:  [0.045563817, -0.13396358] \t -0.8478109 4.5525455 ==> -0.8523673 4.565942\n",
      "81 gradient:  [0.044199944, -0.12995279] \t -0.8523673 4.565942 ==> -0.85678726 4.578937\n",
      "82 gradient:  [0.042876363, -0.12606215] \t -0.85678726 4.578937 ==> -0.8610749 4.591543\n",
      "83 gradient:  [0.04159212, -0.12228823] \t -0.8610749 4.591543 ==> -0.86523414 4.603772\n",
      "84 gradient:  [0.04034877, -0.118626356] \t -0.86523414 4.603772 ==> -0.869269 4.615635\n",
      "85 gradient:  [0.03913927, -0.11507523] \t -0.869269 4.615635 ==> -0.87318295 4.6271424\n",
      "86 gradient:  [0.0379678, -0.11162996] \t -0.87318295 4.6271424 ==> -0.8769797 4.6383057\n",
      "87 gradient:  [0.03683281, -0.108287215] \t -0.8769797 4.6383057 ==> -0.880663 4.649134\n",
      "88 gradient:  [0.03572619, -0.10504651] \t -0.880663 4.649134 ==> -0.8842356 4.659639\n",
      "89 gradient:  [0.0346601, -0.10190034] \t -0.8842356 4.659639 ==> -0.88770163 4.669829\n",
      "90 gradient:  [0.03361988, -0.09885037] \t -0.88770163 4.669829 ==> -0.89106363 4.6797137\n",
      "91 gradient:  [0.032614112, -0.09589076] \t -0.89106363 4.6797137 ==> -0.894325 4.689303\n",
      "92 gradient:  [0.031639338, -0.09301925] \t -0.894325 4.689303 ==> -0.89748895 4.698605\n",
      "93 gradient:  [0.030691147, -0.09023464] \t -0.89748895 4.698605 ==> -0.90055805 4.7076287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 gradient:  [0.029772878, -0.08753276] \t -0.90055805 4.7076287 ==> -0.90353537 4.716382\n",
      "95 gradient:  [0.028879642, -0.08491278] \t -0.90353537 4.716382 ==> -0.90642333 4.7248735\n",
      "96 gradient:  [0.02801776, -0.082369566] \t -0.90642333 4.7248735 ==> -0.9092251 4.7331104\n",
      "97 gradient:  [0.027175426, -0.079904675] \t -0.9092251 4.7331104 ==> -0.91194266 4.741101\n",
      "98 gradient:  [0.026363969, -0.07751179] \t -0.91194266 4.741101 ==> -0.91457903 4.748852\n",
      "99 gradient:  [0.025573254, -0.07519162] \t -0.91457903 4.748852 ==> -0.9171364 4.756371\n",
      "[-0.9171364, 4.756371]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "W_init = sess.run([W,b])\n",
    "print(W_init)\n",
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(prediction)\n",
    "for i in range(100):\n",
    "    grad=sess.run(gradient,feed_dict={x_p: x,y_p: y})\n",
    "    W_old,b_old = sess.run([W,b])\n",
    "    sess.run([W.assign_sub(0.1*grad[0]),b.assign_sub(0.1*grad[1])]) #what about millions of weights?\n",
    "#     sess.run([var.assign_sub(0.1*gradient) for var,gradient in zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES),grad)])\n",
    "    W_new,b_new = sess.run([W,b])\n",
    "    print(i,\"gradient: \",grad, \"\\t\", W_old,b_old, \"==>\",W_new,b_new)\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "[[3.8392346]\n",
      " [2.9220982]\n",
      " [2.004962 ]\n",
      " [1.0878255]]\n",
      "target\n",
      "[[4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(\"prediction\")\n",
    "print(prediction[0])\n",
    "print(\"target\")\n",
    "print(y)\n",
    "# 1000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[0],[1],[1]])\n",
    "#tf.sigmoid() tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your implementation goes here, add more code cells if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on () two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## 1. What is tensorflow?\n",
    "## 2. Why do people use tensorflow?\n",
    "## 3. How to write tensorflow program?\n",
    "### (1). Build dataflow graph\n",
    "### (2). Run dataflow graph and train the weights\n",
    "## 4. (Bonus) What is feature learning and feature crafting (feature engineering), Difference, how to do feature crafting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "## 2.\n",
    "\n",
    "## 3.(1). \n",
    "\n",
    "## 3.(2).\n",
    "\n",
    "## 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
