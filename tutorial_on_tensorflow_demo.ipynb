{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(\"tensorflow version {}\".format(tf.VERSION)) # make sure its tensorflow 1.*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"b_constant:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"op:0\", shape=(2, 1), dtype=float32)\n",
      "Tensor(\"op_1:0\", shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#c=a+b\n",
    "#d=c*a\n",
    "g0=tf.Graph()\n",
    "with g0.as_default():\n",
    "    a = tf.constant([[1],[2]], dtype=tf.float32,name='a_constant')\n",
    "    b = tf.constant([[2],[3]], dtype=tf.float32,name='b_constant')\n",
    "    c=tf.add(a,b,name='op')  # c = a + b\n",
    "    d=tf.multiply(c,a,name='op') #d = c * a\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "#building the graph (the actual computation does not happen here, though its tempting to think of that)\n",
    "#build the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.],\n",
      "       [2.]], dtype=float32), array([[3.],\n",
      "       [5.]], dtype=float32), array([[ 3.],\n",
      "       [10.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#computation occurs\n",
    "#start the engine\n",
    "sess0=tf.Session(graph=g0)\n",
    "result=sess0.run([a,c,d])\n",
    "print(result)\n",
    "\n",
    "#visualize the graph\n",
    "writer = tf.summary.FileWriter('.',sess0.graph)\n",
    "writer.flush()\n",
    "\n",
    "sess0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haobei/Projects/Tutorial\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=int32) <tensorflow.python.framework.ops.Graph object at 0xb3c5ed0b8>\n",
      "Tensor(\"a_random:0\", shape=(2, 3), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n",
      "Tensor(\"b:0\", shape=(3, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n",
      "name: \"print\"\n",
      "op: \"PrintV2\"\n",
      "input: \"print_format\"\n",
      "attr {\n",
      "  key: \"output_stream\"\n",
      "  value {\n",
      "    s: \"stderr\"\n",
      "  }\n",
      "}\n",
      " <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n",
      "<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref> <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n",
      "Tensor(\"matmul:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n",
      "Tensor(\"add:0\", shape=(2, 2), dtype=float32) <tensorflow.python.framework.ops.Graph object at 0xb3ca253c8>\n"
     ]
    }
   ],
   "source": [
    "#tensor math matrix\n",
    "#with \"defaultGraph\".as_default():\n",
    "g1=tf.Graph()\n",
    "a0 = tf.constant(2)\n",
    "with g1.as_default():\n",
    "    a = tf.random_normal([2,3], dtype=tf.float32,name='a_random')\n",
    "    b = tf.constant([[1,1],[1,1],[1,1]], dtype=tf.float32,name='b')\n",
    "    op = tf.print(\"value of a\",a,name='print')\n",
    "    var_x = tf.get_variable(\"var_x\", [2,2], dtype=tf.float32, trainable=False,\n",
    "                            initializer=tf.zeros_initializer)\n",
    "    c = tf.matmul(a,b,name='matmul') # a @ b\n",
    "    d = c + var_x #tf.add\n",
    "print(a0,a0.graph)\n",
    "print(a,a.graph)\n",
    "print(b,b.graph)\n",
    "print(op,op.graph)\n",
    "print(var_x,var_x.graph)\n",
    "print(c,c.graph)\n",
    "print(d,d.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine switch\n",
    "sess1=tf.Session(graph=g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print None\n",
      "a [[ 2.3015423  0.0855993  1.1671302]\n",
      " [ 0.6491126 -2.085204   0.8629421]]\n",
      "matmul None\n",
      "c [[ 2.8990245  2.8990245]\n",
      " [-2.5520935 -2.5520935]]\n"
     ]
    }
   ],
   "source": [
    "print('print',sess1.run(op))\n",
    "print('a',sess1.run(a)) #print(a.eval(session=sess))\n",
    "print('matmul',sess1.run('matmul'))\n",
    "print('c',sess1.run('matmul:0')) #c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess1.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'var_x:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#facilitate updates of weights of a neural network\n",
    "with g1.as_default():\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "with g1.as_default():\n",
    "    print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)) \n",
    "    print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1], [2], [3], [4]],dtype=np.float32)\n",
    "y = np.array([[4], [3], [2], [1]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default graph\n",
    "tf.reset_default_graph()\n",
    "# mini-batch \n",
    "x_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"x_placeholder\") # shape is determained at runtime\n",
    "y_p = tf.placeholder(dtype=tf.float32,shape=(None,1),name=\"y_placeholder\")\n",
    "\n",
    "W = tf.get_variable(\"weight\",shape=(1,),dtype=tf.float32,\n",
    "                    initializer=tf.ones_initializer,\n",
    "                    trainable=True)\n",
    "b = tf.get_variable(\"bias\",shape=(1,),dtype=tf.float32,\n",
    "                    initializer=tf.zeros_initializer,\n",
    "                    trainable=True)\n",
    "y_hat = W * x_p + b\n",
    "loss = tf.reduce_mean(tf.square(y_hat - y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session() # session of the default graph\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = tf.gradients(loss,[W,b])\n",
    "#print the design blue print of the engine\n",
    "writer = tf.summary.FileWriter('.',sess.graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.], dtype=float32), array([0.], dtype=float32)]\n",
      "[array([[1.],\n",
      "       [2.],\n",
      "       [3.],\n",
      "       [4.]], dtype=float32), 5.0, [array([5.], dtype=float32), array([0.], dtype=float32)]]\n",
      "0 gradient:  [5.] \t [1.] [0.] ==> [0.5] [0.]\n",
      "1 gradient:  [-2.5] \t [0.5] [0.] ==> [0.75] [0.25]\n",
      "2 gradient:  [2.5] \t [0.75] [0.25] ==> [0.5] [0.325]\n",
      "3 gradient:  [-0.87499976] \t [0.5] [0.325] ==> [0.5875] [0.51]\n",
      "4 gradient:  [1.3624997] \t [0.5875] [0.51] ==> [0.45125002] [0.61425]\n",
      "5 gradient:  [-0.15999997] \t [0.45125002] [0.61425] ==> [0.46725002] [0.765775]\n",
      "6 gradient:  [0.8376255] \t [0.46725002] [0.765775] ==> [0.38348746] [0.878995]\n",
      "7 gradient:  [0.14728665] \t [0.38348746] [0.878995] ==> [0.3687588] [1.0114523]\n",
      "8 gradient:  [0.5886433] \t [0.3687588] [1.0114523] ==> [0.30989447] [1.1247824]\n",
      "9 gradient:  [0.2723292] \t [0.30989447] [1.1247824] ==> [0.28266156] [1.2448788]\n",
      "10 gradient:  [0.46431732] \t [0.28266156] [1.2448788] ==> [0.23622982] [1.3545723]\n",
      "11 gradient:  [0.31630898] \t [0.23622982] [1.3545723] ==> [0.20459892] [1.4655429]\n",
      "12 gradient:  [0.39669847] \t [0.20459892] [1.4655429] ==> [0.16492906] [1.5701349]\n",
      "13 gradient:  [0.3246106] \t [0.16492906] [1.5701349] ==> [0.132468] [1.6736434]\n",
      "14 gradient:  [0.35523653] \t [0.132468] [1.6736434] ==> [0.09694435] [1.7726806]\n",
      "15 gradient:  [0.31756866] \t [0.09694435] [1.7726806] ==> [0.06518748] [1.8696723]\n",
      "16 gradient:  [0.3261733] \t [0.06518748] [1.8696723] ==> [0.03257015] [1.9631441]\n",
      "17 gradient:  [0.30427265] \t [0.03257015] [1.9631441] ==> [0.00214289] [2.0542302]\n",
      "18 gradient:  [0.30329466] \t [0.00214289] [2.0542302] ==> [-0.02818658] [2.1423128]\n",
      "19 gradient:  [0.28876543] \t [-0.02818658] [2.1423128] ==> [-0.05706312] [2.2279434]\n",
      "20 gradient:  [0.28377032] \t [-0.05706312] [2.2279434] ==> [-0.08544015] [2.3108864]\n",
      "21 gradient:  [0.27282953] \t [-0.08544015] [2.3108864] ==> [-0.1127231] [2.3914292]\n",
      "22 gradient:  [0.26629925] \t [-0.1127231] [2.3914292] ==> [-0.13935304] [2.4695048]\n",
      "23 gradient:  [0.2572286] \t [-0.13935304] [2.4695048] ==> [-0.1650759] [2.5452805]\n",
      "24 gradient:  [0.2502637] \t [-0.1650759] [2.5452805] ==> [-0.19010226] [2.6187623]\n",
      "25 gradient:  [0.24227726] \t [-0.19010226] [2.6187623] ==> [-0.21432999] [2.6900609]\n",
      "26 gradient:  [0.23535466] \t [-0.21432999] [2.6900609] ==> [-0.23786545] [2.7592137]\n",
      "27 gradient:  [0.22808671] \t [-0.23786545] [2.7592137] ==> [-0.26067412] [2.8263037]\n",
      "28 gradient:  [0.22140694] \t [-0.26067412] [2.8263037] ==> [-0.2828148] [2.89138]\n",
      "29 gradient:  [0.21467817] \t [-0.2828148] [2.89138] ==> [-0.3042826] [2.9545114]\n",
      "30 gradient:  [0.20831811] \t [-0.3042826] [2.9545114] ==> [-0.32511443] [3.0157504]\n",
      "31 gradient:  [0.20203555] \t [-0.32511443] [3.0157504] ==> [-0.345318] [3.0751576]\n",
      "32 gradient:  [0.19601834] \t [-0.345318] [3.0751576] ==> [-0.3649198] [3.132785]\n",
      "33 gradient:  [0.1901282] \t [-0.3649198] [3.132785] ==> [-0.38393262] [3.188688]\n",
      "34 gradient:  [0.18445075] \t [-0.38393262] [3.188688] ==> [-0.4023777] [3.2429168]\n",
      "35 gradient:  [0.17891872] \t [-0.4023777] [3.2429168] ==> [-0.42026958] [3.2955222]\n",
      "36 gradient:  [0.17356741] \t [-0.42026958] [3.2955222] ==> [-0.43762633] [3.3465526]\n",
      "37 gradient:  [0.16836822] \t [-0.43762633] [3.3465526] ==> [-0.45446315] [3.3960552]\n",
      "38 gradient:  [0.16332877] \t [-0.45446315] [3.3960552] ==> [-0.47079602] [3.4440758]\n",
      "39 gradient:  [0.1584388] \t [-0.47079602] [3.4440758] ==> [-0.4866399] [3.4906588]\n",
      "40 gradient:  [0.15369546] \t [-0.4866399] [3.4906588] ==> [-0.50200945] [3.535847]\n",
      "41 gradient:  [0.1490928] \t [-0.50200945] [3.535847] ==> [-0.5169187] [3.5796824]\n",
      "42 gradient:  [0.14463103] \t [-0.5169187] [3.5796824] ==> [-0.53138185] [3.6222053]\n",
      "43 gradient:  [0.1402986] \t [-0.53138185] [3.6222053] ==> [-0.5454117] [3.663455]\n",
      "44 gradient:  [0.13609934] \t [-0.5454117] [3.663455] ==> [-0.55902165] [3.7034698]\n",
      "45 gradient:  [0.13202393] \t [-0.55902165] [3.7034698] ==> [-0.572224] [3.7422867]\n",
      "46 gradient:  [0.12807322] \t [-0.572224] [3.7422867] ==> [-0.58503133] [3.7799413]\n",
      "47 gradient:  [0.12423646] \t [-0.58503133] [3.7799413] ==> [-0.59745497] [3.8164687]\n",
      "48 gradient:  [0.12051904] \t [-0.59745497] [3.8164687] ==> [-0.60950685] [3.8519025]\n",
      "49 gradient:  [0.11690974] \t [-0.60950685] [3.8519025] ==> [-0.6211978] [3.8862753]\n",
      "50 gradient:  [0.11340904] \t [-0.6211978] [3.8862753] ==> [-0.63253874] [3.919619]\n",
      "51 gradient:  [0.11001432] \t [-0.63253874] [3.919619] ==> [-0.64354014] [3.9519646]\n",
      "52 gradient:  [0.10672092] \t [-0.64354014] [3.9519646] ==> [-0.65421224] [3.9833417]\n",
      "53 gradient:  [0.10352492] \t [-0.65421224] [3.9833417] ==> [-0.6645647] [4.0137796]\n",
      "54 gradient:  [0.10042715] \t [-0.6645647] [4.0137796] ==> [-0.67460746] [4.043306]\n",
      "55 gradient:  [0.09741747] \t [-0.67460746] [4.043306] ==> [-0.6843492] [4.0719485]\n",
      "56 gradient:  [0.09450483] \t [-0.6843492] [4.0719485] ==> [-0.6937997] [4.0997334]\n",
      "57 gradient:  [0.09167159] \t [-0.6937997] [4.0997334] ==> [-0.7029668] [4.1266866]\n",
      "58 gradient:  [0.08893061] \t [-0.7029668] [4.1266866] ==> [-0.7118599] [4.1528325]\n",
      "59 gradient:  [0.08626425] \t [-0.7118599] [4.1528325] ==> [-0.7204863] [4.178196]\n",
      "60 gradient:  [0.0836854] \t [-0.7204863] [4.178196] ==> [-0.72885484] [4.2028]\n",
      "61 gradient:  [0.0811764] \t [-0.72885484] [4.2028] ==> [-0.73697245] [4.2266674]\n",
      "62 gradient:  [0.07875013] \t [-0.73697245] [4.2266674] ==> [-0.7448475] [4.24982]\n",
      "63 gradient:  [0.07638896] \t [-0.7448475] [4.24982] ==> [-0.75248635] [4.2722797]\n",
      "64 gradient:  [0.07410336] \t [-0.75248635] [4.2722797] ==> [-0.7598967] [4.294067]\n",
      "65 gradient:  [0.07188404] \t [-0.7598967] [4.294067] ==> [-0.7670851] [4.3152018]\n",
      "66 gradient:  [0.06973267] \t [-0.7670851] [4.3152018] ==> [-0.77405834] [4.335704]\n",
      "67 gradient:  [0.06764412] \t [-0.77405834] [4.335704] ==> [-0.78082275] [4.3555923]\n",
      "68 gradient:  [0.06561995] \t [-0.78082275] [4.3555923] ==> [-0.78738475] [4.374885]\n",
      "69 gradient:  [0.06365418] \t [-0.78738475] [4.374885] ==> [-0.79375017] [4.3936005]\n",
      "70 gradient:  [0.06174994] \t [-0.79375017] [4.3936005] ==> [-0.79992515] [4.4117556]\n",
      "71 gradient:  [0.05990064] \t [-0.79992515] [4.4117556] ==> [-0.80591524] [4.429367]\n",
      "72 gradient:  [0.0581069] \t [-0.80591524] [4.429367] ==> [-0.8117259] [4.446451]\n",
      "73 gradient:  [0.05636728] \t [-0.8117259] [4.446451] ==> [-0.81736267] [4.463024]\n",
      "74 gradient:  [0.05468082] \t [-0.81736267] [4.463024] ==> [-0.82283074] [4.4791007]\n",
      "75 gradient:  [0.05304253] \t [-0.82283074] [4.4791007] ==> [-0.828135] [4.494696]\n",
      "76 gradient:  [0.0514555] \t [-0.828135] [4.494696] ==> [-0.83328056] [4.5098243]\n",
      "77 gradient:  [0.04991293] \t [-0.83328056] [4.5098243] ==> [-0.83827186] [4.5245]\n",
      "78 gradient:  [0.04842162] \t [-0.83827186] [4.5245] ==> [-0.843114] [4.538736]\n",
      "79 gradient:  [0.04696894] \t [-0.843114] [4.538736] ==> [-0.8478109] [4.5525455]\n",
      "80 gradient:  [0.04556382] \t [-0.8478109] [4.5525455] ==> [-0.8523673] [4.565942]\n",
      "81 gradient:  [0.04419994] \t [-0.8523673] [4.565942] ==> [-0.85678726] [4.578937]\n",
      "82 gradient:  [0.04287636] \t [-0.85678726] [4.578937] ==> [-0.8610749] [4.591543]\n",
      "83 gradient:  [0.04159212] \t [-0.8610749] [4.591543] ==> [-0.86523414] [4.603772]\n",
      "84 gradient:  [0.04034877] \t [-0.86523414] [4.603772] ==> [-0.869269] [4.615635]\n",
      "85 gradient:  [0.03913927] \t [-0.869269] [4.615635] ==> [-0.87318295] [4.6271424]\n",
      "86 gradient:  [0.0379678] \t [-0.87318295] [4.6271424] ==> [-0.8769797] [4.6383057]\n",
      "87 gradient:  [0.03683281] \t [-0.8769797] [4.6383057] ==> [-0.880663] [4.649134]\n",
      "88 gradient:  [0.03572619] \t [-0.880663] [4.649134] ==> [-0.8842356] [4.659639]\n",
      "89 gradient:  [0.0346601] \t [-0.8842356] [4.659639] ==> [-0.88770163] [4.669829]\n",
      "90 gradient:  [0.03361988] \t [-0.88770163] [4.669829] ==> [-0.89106363] [4.6797137]\n",
      "91 gradient:  [0.03261411] \t [-0.89106363] [4.6797137] ==> [-0.894325] [4.689303]\n",
      "92 gradient:  [0.03163934] \t [-0.894325] [4.689303] ==> [-0.89748895] [4.698605]\n",
      "93 gradient:  [0.03069115] \t [-0.89748895] [4.698605] ==> [-0.90055805] [4.7076287]\n",
      "94 gradient:  [0.02977288] \t [-0.90055805] [4.7076287] ==> [-0.90353537] [4.716382]\n",
      "95 gradient:  [0.02887964] \t [-0.90353537] [4.716382] ==> [-0.90642333] [4.7248735]\n",
      "96 gradient:  [0.02801776] \t [-0.90642333] [4.7248735] ==> [-0.9092251] [4.7331104]\n",
      "97 gradient:  [0.02717543] \t [-0.9092251] [4.7331104] ==> [-0.91194266] [4.741101]\n",
      "98 gradient:  [0.02636397] \t [-0.91194266] [4.741101] ==> [-0.91457903] [4.748852]\n",
      "99 gradient:  [0.02557325] \t [-0.91457903] [4.748852] ==> [-0.9171364] [4.756371]\n",
      "[array([-0.9171364], dtype=float32), array([4.756371], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "W_init = sess.run([W,b])\n",
    "print(W_init)\n",
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(prediction)\n",
    "for i in range(100):\n",
    "    grad=sess.run(gradient,feed_dict={x_p: x,y_p: y})\n",
    "    W_old,b_old = sess.run([W,b])\n",
    "#     sess.run([W.assign_sub(0.1*grad[0]),b.assign_sub(0.1*grad[1])]) what about millions of weights?\n",
    "    sess.run([var.assign_sub(0.1*gradient) for var,gradient in zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES),grad)])\n",
    "    W_new,b_new = sess.run([W,b])\n",
    "    print(i,\"gradient: \",grad, \"\\t\", W_old,b_old, \"==>\",W_new,b_new)\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run([y_hat,loss,gradient],feed_dict={x_p: x,y_p: y})\n",
    "print(\"prediction\")\n",
    "print(prediction[0])\n",
    "print(\"target\")\n",
    "print(y)\n",
    "# 1000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[0],[1],[1]])\n",
    "#tf.sigmoid() tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your implementation goes here, add more code cells if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single sigmoid neuron prediction on () two-dimension data\n",
    "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model\n",
    "vis_inputs = np.random.uniform(size=(10000,2))\n",
    "predictions = sess.run(y_hat,feed_dict={x_p:vis_inputs})\n",
    "print(predictions.shape)\n",
    "colors = list(map(lambda p: 'red' if p < 0.5 else 'blue', predictions))\n",
    "plt.scatter(vis_inputs[:,0], vis_inputs[:,1], 1, colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
